{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===\n",
    "тут шифровальщик и \"датасет\" хдд\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = list(\"абвгдеёжзийклмнопрстуфхцчшщъыьэюя\") # Отдельный алфавит для шифра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# шифровальщик\n",
    "def encode(text, shift):\n",
    "    encrypted_text = \"\"\n",
    "    for ch in text:\n",
    "        is_upper = ch.isupper()\n",
    "        ch = ch.lower()\n",
    "        if ch in ALPHABET:\n",
    "            index = ALPHABET.index(ch)\n",
    "            new_index = (index + shift) % len(ALPHABET)\n",
    "            new_letter = ALPHABET[new_index]\n",
    "            if is_upper:\n",
    "                new_letter = new_letter.upper()\n",
    "            encrypted_text += new_letter\n",
    "        else:\n",
    "            encrypted_text += ch\n",
    "    return encrypted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оригинал: Пример зашифрованного текста!\n",
      "Шифровка: Тулпзу кгылчусегррсёс хзнфхг!\n",
      "Оригинал: Вот это мдааа...\n",
      "Шифровка: Есх ахс пжггг...\n",
      "Оригинал: Чоч))0)\n",
      "Шифровка: Ъсъ))0)\n"
     ]
    }
   ],
   "source": [
    "# Проверка работы шифровальщика\n",
    "texts = [\"Пример зашифрованного текста!\",\n",
    "         \"Вот это мдааа...\",\n",
    "         \"Чоч))0)\"]\n",
    "shift = 3\n",
    "for text in texts:\n",
    "    encrypted_text = encode(text, shift)\n",
    "    print(f\"Оригинал: {text}\")\n",
    "    print(f\"Шифровка: {encrypted_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "del texts, shift\n",
    "# Создание \"датасета\"\n",
    "train_data = [\n",
    "    \"я пошла в школу.\",\n",
    "    \"мама купила книгу.\",\n",
    "    \"выпал первый снег.\",\n",
    "    \"Она уехала за границу.\",\n",
    "    \"Друг позвал гулять.\",\n",
    "    \"Взошло солнце и осветило поляну.\",\n",
    "    \"Птичка села на ветку и запела.\",\n",
    "    \"В лесу раздавался стук топора\",\n",
    "    \"Капитан хмуро осмотрел палубу.\",\n",
    "    \"А на море белый песок.\",\n",
    "    \"Как хорошо когда есть друг.\",\n",
    "    \"Он всегда поможет и поддержит.\",\n",
    "    \"А если печаль нагрянет вдруг.\",\n",
    "    \"Он развеселит и утешит.\",\n",
    "    \"Так что не печалься и не грусти.\",\n",
    "    \"Помни милый, добрый друг.\",\n",
    "    \"Тепло и радость в душу ты пусти.\",\n",
    "    \"Ведь прекрасен мир вокруг.\",\n",
    "    \"На опушке стоит дом.\",\n",
    "    \"Злой варвик сидит в нём.\",\n",
    "    \"Ты в лес гулять не ходи.\",\n",
    "    \"Зов предков в нем не буди.\",\n",
    "    \"Красивая девушка стоит с букетом.\",\n",
    "    \"На перон приходит поезд.\",\n",
    "    \"Врач поставил верный диагноз.\",\n",
    "    \"Мастер закончил свою работу.\",\n",
    "    \"Вдруг в соседней комнате раздался стук.\",\n",
    "    \"На стене висит красивая картина.\",\n",
    "    \"Мальчик играет на компьютере.\"]\n",
    "test_data = [\n",
    "    \"Пивка для научного рывка!\",\n",
    "    \"Моя нейросеточка всё правильно задезинкриптит.\",\n",
    "    \"Доброе утро, братья славяне!\",\n",
    "    \"Бу! Испугался? Не бойся, я Нейронка, я тебя не обижу.\",\n",
    "    \"Поставьте зачёт пж пж пж\"]\n",
    "\n",
    "encrypts_train, encrypts_test = [], []\n",
    "\n",
    "for text in train_data:\n",
    "    shift = 3#random.randint(1,4) К сожалу для разных сдвигов нужно в миллиард раз больше данных\n",
    "    encrypts_train.append(encode(text, shift))\n",
    "for text in test_data:\n",
    "    shift = 3#random.randint(1,4)\n",
    "    encrypts_test.append(encode(text, shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['в тсыог е ынсоц.',\n",
       " 'пгпг нцтлог нрлёц.',\n",
       " 'еютго тзуеюм фрзё.',\n",
       " 'Срг цзшгог кг ёугрлщц.',\n",
       " 'Жуцё тскего ёцовхя.',\n",
       " 'Ексыос фсорщз л сфезхлос тсоврц.',\n",
       " 'Тхлънг фзог рг езхнц л кгтзог.',\n",
       " 'Е озфц угкжгегофв фхцн хстсуг',\n",
       " 'Нгтлхгр шпцус сфпсхузо тгоцдц.',\n",
       " 'Г рг псуз дзоюм тзфсн.',\n",
       " 'Нгн шсусыс нсёжг зфхя жуцё.',\n",
       " 'Ср ефзёжг тспсйзх л тсжжзуйлх.',\n",
       " 'Г зфол тзъгоя ргёуврзх ежуцё.',\n",
       " 'Ср угкезфзолх л цхзылх.',\n",
       " 'Хгн ъхс рз тзъгояфв л рз ёуцфхл.',\n",
       " 'Тспрл плоюм, жсдуюм жуцё.',\n",
       " 'Хзтос л угжсфхя е жцыц хю тцфхл.',\n",
       " 'Езжя тузнугфзр плу еснуцё.',\n",
       " 'Рг стцынз фхслх жсп.',\n",
       " 'Косм егуелн флжлх е рип.',\n",
       " 'Хю е озф ёцовхя рз шсжл.',\n",
       " 'Ксе тузжнсе е рзп рз дцжл.',\n",
       " 'Нугфлегв жзецынг фхслх ф дцнзхсп.',\n",
       " 'Рг тзуср тулшсжлх тсзкж.',\n",
       " 'Еугъ тсфхгело езурюм жлгёрск.',\n",
       " 'Пгфхзу кгнсръло фесб угдсхц.',\n",
       " 'Ежуцё е фсфзжрзм нспргхз угкжгофв фхцн.',\n",
       " 'Рг фхзрз елфлх нугфлегв нгухлрг.',\n",
       " 'Пгояълн лёугзх рг нсптябхзуз.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encrypts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Тленг жов ргцърсёс уюенг!',\n",
       " 'Псв рзмусфзхсънг ефи тугелоярс кгжзклрнултхлх.',\n",
       " 'Жсдусз цхус, дугхяв фогеврз!',\n",
       " 'Дц! Лфтцёгофв? Рз дсмфв, в Рзмусрнг, в хздв рз сдлйц.',\n",
       " 'Тсфхгеяхз кгъих тй тй тй']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encrypts_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===\n",
    "внутренности сеточки\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры\n",
    "CHARS = {ch: idx for idx, ch in enumerate(ALPHABET)}\n",
    "UNK_IDX = len(CHARS)  # Ну короче чтобы нан имел свой индекс вот да\n",
    "CHARS[\"none\"] = UNK_IDX\n",
    "INDEX_TO_CHAR = [w for w in CHARS]\n",
    "CHARS_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}\n",
    "VOCAB_SIZE = len(INDEX_TO_CHAR)\n",
    "EMBEDDING_DIM = 16\n",
    "HIDDEN_SIZE = 32\n",
    "OUTPUT_SIZE = VOCAB_SIZE # Да я, а что?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderNET(torch.nn.Module): # Класс для нашей нейроночки\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(DecoderNET, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = torch.nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # Преобразуем индексы в эмбеддинги\n",
    "        output, hidden = self.rnn(embedded)  # Пропускаем через RNN\n",
    "        output = self.fc(output)  # Преобразуем в предсказания символов\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных\n",
    " \n",
    "def prepare_sequence(text, vocab=CHARS):\n",
    "    indices = []\n",
    "    uppercase_indices = [] # Это шобы отдельно хранить индексы заглавных букв\n",
    "    \n",
    "    for i, char in enumerate(text):\n",
    "        # Проверяем, если буква заглавная, сохраняем индекс и переводим в строчный\n",
    "        if char.isupper():\n",
    "            uppercase_indices.append(i)\n",
    "            char = char.lower()\n",
    "        \n",
    "        # Получаем индекс символа в словаре или UNK_IDX, если его нет в словаре\n",
    "        indices.append(vocab.get(char, UNK_IDX))\n",
    "    \n",
    "    # Преобразуем в тензор\n",
    "    return torch.tensor(indices, dtype=torch.long), uppercase_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расшифровка\n",
    "def decode_sequence(model, cipher_seq, original_text, uppercase_indices):\n",
    "    with torch.no_grad():\n",
    "        output = model(cipher_seq.unsqueeze(0))\n",
    "        decoded_indices = torch.argmax(output, dim=2).squeeze().tolist()\n",
    "        \n",
    "        # Собираем расшифрованный текст с учетом оригинальных символов\n",
    "        decoded_chars = []\n",
    "        for i, idx in enumerate(decoded_indices):\n",
    "            if original_text[i] in CHARS or original_text[i].isspace() or not original_text[i].isalpha():\n",
    "                # Если символ есть в словаре или это пробел/знак препинания, берем исходный\n",
    "                decoded_char = original_text[i] if not original_text[i].isalpha() else ALPHABET[idx]\n",
    "            else:\n",
    "                # Если символ отсутствует в словаре и это не пробел/знак, помечаем как нан\n",
    "                decoded_char = ALPHABET[idx] if 0 <= idx < len(ALPHABET) else \"none\"\n",
    "            decoded_chars.append(decoded_char)\n",
    "        \n",
    "        # Применяем заглавные буквы к нужным символам\n",
    "        for idx in uppercase_indices:\n",
    "            if 0 <= idx < len(decoded_chars):\n",
    "                decoded_chars[idx] = decoded_chars[idx].upper()\n",
    "                \n",
    "    return ''.join(decoded_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция обучения\n",
    "def train(model, data, encrypts, epochs=60, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for plain_text, cipher_text in zip(data, encrypts):\n",
    "            model.train()\n",
    "\n",
    "            # Готовим данные\n",
    "            input_seq, input_uppercase_indices = prepare_sequence(cipher_text)\n",
    "            target_seq, _ = prepare_sequence(plain_text)\n",
    "            input_seq = input_seq.unsqueeze(0)\n",
    "            target_seq = target_seq.unsqueeze(0)\n",
    "\n",
    "            # Обучение\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_seq)\n",
    "            loss = criterion(output.view(-1, OUTPUT_SIZE), target_seq.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Печать средней ошибки каждые 10 эпох\n",
    "        if epoch % 10 == 0:\n",
    "            avg_loss = total_loss / len(data)\n",
    "            print(f\"Epoch {epoch}, Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция тестирования\n",
    "def test(model, test_data, encrypts_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for original_text, cipher_text in zip(test_data, encrypts_test):\n",
    "            input_seq, input_uppercase_indices = prepare_sequence(cipher_text)\n",
    "            input_seq = input_seq.unsqueeze(0)\n",
    "\n",
    "            # Расшифровка\n",
    "            decoded_text = decode_sequence(model, input_seq[0], cipher_text, input_uppercase_indices)\n",
    "            \n",
    "            # Вывод результатов\n",
    "            print(f\"Зашифрованный текст: {cipher_text}\")\n",
    "            print(f\"Ожидаемый текст:   {original_text}\")\n",
    "            print(f\"Расшифрованный текст: {decoded_text}\")\n",
    "            print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===\n",
    "Гы\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модельку\n",
    "model = DecoderNET(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, OUTPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Average Loss: 1.9622\n",
      "Epoch 10, Average Loss: 0.0047\n",
      "Epoch 20, Average Loss: 0.0015\n",
      "Epoch 30, Average Loss: 0.0008\n",
      "Epoch 40, Average Loss: 0.0005\n",
      "Epoch 50, Average Loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# Обучаем\n",
    "train(model, train_data, encrypts_train, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зашифрованный текст: Тленг жов ргцърсёс уюенг!\n",
      "Ожидаемый текст:   Пивка для научного рывка!\n",
      "Расшифрованный текст: Пивка для научного рывка!\n",
      "----------------------------------------\n",
      "Зашифрованный текст: Псв рзмусфзхсънг ефи тугелоярс кгжзклрнултхлх.\n",
      "Ожидаемый текст:   Моя нейросеточка всё правильно задезинкриптит.\n",
      "Расшифрованный текст: Моя нейросеточка всё правильно задезинкриптит.\n",
      "----------------------------------------\n",
      "Зашифрованный текст: Жсдусз цхус, дугхяв фогеврз!\n",
      "Ожидаемый текст:   Доброе утро, братья славяне!\n",
      "Расшифрованный текст: Доброе утро, братья славяне!\n",
      "----------------------------------------\n",
      "Зашифрованный текст: Дц! Лфтцёгофв? Рз дсмфв, в Рзмусрнг, в хздв рз сдлйц.\n",
      "Ожидаемый текст:   Бу! Испугался? Не бойся, я Нейронка, я тебя не обижу.\n",
      "Расшифрованный текст: Бу! Испугался? Не бойся, я Нейронка, я тебя не обижу.\n",
      "----------------------------------------\n",
      "Зашифрованный текст: Тсфхгеяхз кгъих тй тй тй\n",
      "Ожидаемый текст:   Поставьте зачёт пж пж пж\n",
      "Расшифрованный текст: Поставьте зачёт пж пж пж\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Проверяем\n",
    "test(model, test_data, encrypts_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
